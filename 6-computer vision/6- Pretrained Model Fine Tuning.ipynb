{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir = Path(\"cats_vs_dogs_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(new_base_dir / \"train\", image_size=(180, 180), batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(new_base_dir / \"validation\", image_size=(180, 180), batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(new_base_dir / \"test\", image_size=(180, 180), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Freezing all layers until the fourth from the last**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vgg16.trainable = True\n",
    "\n",
    "for layer in vgg16.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fine-tuning the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = Sequential([RandomFlip(\"horizontal\"), RandomRotation(0.1),RandomZoom(0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(180, 180, 3))\n",
    "\n",
    "x = augmentation(inputs)\n",
    "\n",
    "x = preprocess_input(x)\n",
    "\n",
    "x = vgg16(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=RMSprop(learning_rate=1e-5), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "63/63 [==============================] - 25s 279ms/step - loss: 4.4741 - accuracy: 0.6980 - val_loss: 0.9290 - val_accuracy: 0.8950\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 15s 232ms/step - loss: 1.1769 - accuracy: 0.8380 - val_loss: 0.4402 - val_accuracy: 0.9300\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 15s 231ms/step - loss: 0.4967 - accuracy: 0.8900 - val_loss: 0.3091 - val_accuracy: 0.9440\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 15s 231ms/step - loss: 0.3569 - accuracy: 0.9165 - val_loss: 0.2757 - val_accuracy: 0.9520\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 0.2956 - accuracy: 0.9230 - val_loss: 0.2278 - val_accuracy: 0.9590\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 0.2438 - accuracy: 0.9300 - val_loss: 0.2076 - val_accuracy: 0.9630\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 0.1981 - accuracy: 0.9490 - val_loss: 0.2078 - val_accuracy: 0.9640\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 14s 230ms/step - loss: 0.1364 - accuracy: 0.9600 - val_loss: 0.1986 - val_accuracy: 0.9640\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 14s 229ms/step - loss: 0.1399 - accuracy: 0.9605 - val_loss: 0.2106 - val_accuracy: 0.9670\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 14s 229ms/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.2212 - val_accuracy: 0.9680\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 0.0835 - accuracy: 0.9750 - val_loss: 0.2165 - val_accuracy: 0.9680\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 15s 231ms/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 0.2073 - val_accuracy: 0.9700\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 15s 231ms/step - loss: 0.0593 - accuracy: 0.9805 - val_loss: 0.2258 - val_accuracy: 0.9750\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 15s 230ms/step - loss: 0.0716 - accuracy: 0.9760 - val_loss: 0.2398 - val_accuracy: 0.9690\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.2522 - val_accuracy: 0.9670\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 0.0429 - accuracy: 0.9880 - val_loss: 0.2684 - val_accuracy: 0.9680\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 15s 232ms/step - loss: 0.0396 - accuracy: 0.9890 - val_loss: 0.2807 - val_accuracy: 0.9670\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 15s 232ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.2981 - val_accuracy: 0.9720\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.3136 - val_accuracy: 0.9640\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 15s 236ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.2646 - val_accuracy: 0.9680\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.3261 - val_accuracy: 0.9680\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.2851 - val_accuracy: 0.9690\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.0199 - accuracy: 0.9910 - val_loss: 0.2768 - val_accuracy: 0.9710\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.3000 - val_accuracy: 0.9680\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 15s 234ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.3336 - val_accuracy: 0.9710\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 15s 234ms/step - loss: 0.0225 - accuracy: 0.9940 - val_loss: 0.3223 - val_accuracy: 0.9740\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.0194 - accuracy: 0.9965 - val_loss: 0.3375 - val_accuracy: 0.9750\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 15s 236ms/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.3598 - val_accuracy: 0.9710\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 15s 239ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.2905 - val_accuracy: 0.9720\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 15s 238ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.3226 - val_accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(filepath=\"fine_tuning.keras\", save_best_only=True, monitor=\"val_loss\")]\n",
    "history = model.fit(train_dataset, epochs=30, validation_data=validation_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 5s 72ms/step - loss: 0.1795 - accuracy: 0.9625\n",
      "Test accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"fine_tuning.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter08_intro-to-dl-for-computer-vision.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
